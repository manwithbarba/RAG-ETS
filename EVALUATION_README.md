# Protocolo de Evaluaci칩n del Sistema RAG de ETS

## 1. Introducci칩n

Este documento describe el protocolo para evaluar el rendimiento del sistema de Generaci칩n Aumentada por Recuperaci칩n (RAG). El objetivo es medir la calidad y fiabilidad de las respuestas del sistema de una manera estructurada y repetible.

La evaluaci칩n se divide en dos enfoques complementarios:

1.  **Evaluaci칩n Cualitativa:** Basada en el feedback directo del usuario experto.
2.  **Evaluaci칩n Cuantitativa:** Basada en m칠tricas automatizadas utilizando un framework especializado (`ragas`).

## 2. Requisitos Previos

1.  **Proyecto Configurado:** El proyecto debe estar completamente instalado (`pip install -r requirements.txt`).
2.  **Base de Datos Creada:** El script `ingest.py` debe haber sido ejecutado con los documentos finales.
3.  **API Key de OpenAI:** Para la evaluaci칩n cuantitativa, el framework `ragas` utiliza un LLM (por defecto, de OpenAI) para "juzgar" la calidad de las respuestas. Es necesario tener una API key de OpenAI.

---

## 3. Evaluaci칩n Cualitativa (Feedback de Usuario)

Este m칠todo proporciona informaci칩n r치pida y directa sobre el rendimiento percibido del sistema.

### Proceso

1.  **Iniciar la Aplicaci칩n:**
    ```bash
    streamlit run app.py
    ```
2.  **Realizar Consultas:** Interact칰a con la aplicaci칩n realizando una amplia variedad de preguntas. Prueba preguntas f치ciles, dif칤ciles, espec칤ficas y generales.
3.  **Registrar Feedback:** Despu칠s de cada respuesta generada, utiliza los botones de calificaci칩n:
    - **游녨 (Buena respuesta):** Si la respuesta es correcta, relevante y est치 bien fundamentada en las fuentes.
    - **游녩 (Mala respuesta):** Si la respuesta es incorrecta, irrelevante, incompleta o no cita correctamente las fuentes.

### Resultado

Cada vez que se presiona un bot칩n, se a침ade una nueva l칤nea al archivo `feedback.csv` en la ra칤z del proyecto. Este archivo contiene:

- `timestamp`: Fecha y hora de la evaluaci칩n.
- `question`: La pregunta realizada.
- `answer`: La respuesta generada por el sistema.
- `context`: Las fuentes que el sistema utiliz칩.
- `rating`: Tu calificaci칩n (游녨 o 游녩).

El an치lisis de este archivo permite identificar patrones en las preguntas que el sistema maneja bien o mal.

---

## 4. Evaluaci칩n Cuantitativa (M칠tricas con `ragas`)

Este m칠todo proporciona puntuaciones num칠ricas y objetivas sobre diferentes aspectos del rendimiento del sistema.

### Paso 1: Crear el "Golden Set" de Evaluaci칩n

Esta es la tarea m치s importante. Consiste en crear un dataset de referencia.

- **Acci칩n:** Crea un archivo llamado `eval_dataset.csv` en la ra칤z del proyecto.
- **Formato:** El archivo debe tener exactamente las siguientes 3 columnas:
  - `question`: Una pregunta de prueba.
  - `ground_truth_answer`: La respuesta "ideal" que un experto humano escribir칤a.
  - `ground_truth_context`: El texto exacto de los documentos que justifica la respuesta ideal.

- **Ejemplo de una fila en `eval_dataset.csv`:**
  ```csv
  question,ground_truth_answer,ground_truth_context
  "쮺u치l es la recomendaci칩n para el uso de f치rmaco X en monoterapia?","El f치rmaco X no se recomienda en monoterapia para pacientes con la condici칩n Y, seg칰n la gu칤a de pr치ctica cl칤nica.","La gu칤a de pr치ctica cl칤nica establece en la secci칩n 4.1 que 'el uso de f치rmaco X en monoterapia no est치 recomendado para la condici칩n Y'."
  ```

### Paso 2: Configurar el Entorno

- **Acci칩n:** Abre una terminal en la carpeta del proyecto y configura tu clave de API de OpenAI como una variable de entorno.
  ```bash
  # En Windows
  set OPENAI_API_KEY=sk-...

  # En macOS/Linux
  export OPENAI_API_KEY=sk-...
  ```

### Paso 3: Ejecutar el Script de Evaluaci칩n

- **Acci칩n:** Una vez que tu `eval_dataset.csv` est칠 listo y la clave API configurada, ejecuta el script:
  ```bash
  python evaluate.py
  ```

### Paso 4: Interpretar los Resultados

El script generar치 un informe con una puntuaci칩n de 0 a 1 para cada una de las siguientes m칠tricas:

- **`faithfulness` (Fidelidad):** Mide si la respuesta generada se apega a los hechos presentados en el contexto recuperado. Una puntuaci칩n baja indica que el LLM est치 "alucinando" o inventando informaci칩n.
- **`answer_relevancy` (Relevancia de la Respuesta):** Mide qu칠 tan relevante es la respuesta para la pregunta. Una puntuaci칩n baja indica que la respuesta se desv칤a del tema.
- **`context_precision` (Precisi칩n del Contexto):** Mide si los fragmentos de texto recuperados son relevantes para la pregunta. Es una medida de la calidad del sistema de b칰squeda (retriever).
- **`context_recall` (Recuperaci칩n del Contexto):** Mide si el retriever fue capaz de encontrar TODA la informaci칩n necesaria para componer la respuesta ideal. Una puntuaci칩n baja indica que el retriever no est치 encontrando los fragmentos correctos.

**Acciones seg칰n los resultados:**
- Si `faithfulness` es bajo -> Refinar el prompt en `app.py` para ser m치s estricto.
- Si `context_recall` o `context_precision` son bajos -> Experimentar con la estrategia de `chunking` en `ingest.py` o con el valor de `k` en la interfaz.
