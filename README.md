# Sistema RAG para Consulta de Evaluaciones de Tecnolog√≠as Sanitarias (ETS)

**Autor:** Juli√°n S√°nchez Viamonte

## 1. Objetivos del Proyecto

Este proyecto implementa un sistema de **Generaci√≥n Aumentada por Recuperaci√≥n (RAG)** dise√±ado para permitir la consulta en lenguaje natural de una base de conocimiento privada compuesta por informes y documentos de Evaluaciones de Tecnolog√≠as Sanitarias (ETS).

Los objetivos principales son:

- **Respuestas Basadas en Evidencia:** Asegurar que todas las respuestas generadas por el sistema se basen estrictamente en el contenido de los documentos proporcionados, evitando la invenci√≥n de informaci√≥n (alucinaciones).
- **Trazabilidad y Confianza:** Proveer citas en l√≠nea en las respuestas generadas, permitiendo al usuario final verificar qu√© fragmento de qu√© documento fuente respalda cada afirmaci√≥n.
- **Interfaz Intuitiva:** Ofrecer una interfaz de usuario web simple e interactiva para que usuarios no t√©cnicos puedan realizar consultas complejas f√°cilmente.
- **Arquitectura Local y Abierta:** Construir el sistema utilizando exclusivamente modelos y herramientas de c√≥digo abierto, garantizando la privacidad de los datos y la soberan√≠a sobre la infraestructura.

## 2. Stack Tecnol√≥gico

- **Lenguaje:** Python
- **Framework RAG:** LangChain
- **Interfaz Web:** Streamlit
- **Base de Datos Vectorial:** ChromaDB
- **Modelo de Embeddings:** `sentence-transformers/all-MiniLM-L6-v2` (para convertir texto en vectores)
- **Modelo de Lenguaje (LLM):** `Meta-Llama-3.1-8B-Instruct-GGUF` (cargado localmente v√≠a `llama-cpp-python`)

## 3. Estructura del Proyecto

```
rag-evaluaciones-salud/
‚îÇ
‚îú‚îÄ‚îÄ documentos/               # Carpeta para depositar los archivos fuente (.pdf, .docx).
‚îú‚îÄ‚îÄ models/                   # (Opcional) Se puede usar para guardar modelos descargados.
‚îú‚îÄ‚îÄ vectorstores/
‚îÇ   ‚îî‚îÄ‚îÄ db/                   # Base de datos vectorial ChromaDB generada por la ingesta.
‚îÇ
‚îú‚îÄ‚îÄ app.py                    # Script principal de la aplicaci√≥n web Streamlit.
‚îú‚îÄ‚îÄ ingest.py                 # Script para procesar los documentos y crear la base de datos.
‚îú‚îÄ‚îÄ requirements.txt          # Lista de dependencias de Python.
‚îî‚îÄ‚îÄ README.md                 # Este archivo.
```

- **`app.py`**: Lanza la interfaz web. Carga el LLM y la base de datos vectorial, procesa la entrada del usuario, ejecuta la cadena RAG y muestra la respuesta con citas.
- **`ingest.py`**: Lee los documentos de la carpeta `documentos/`, los divide en fragmentos (chunks), genera los embeddings y los almacena en la base de datos ChromaDB en `vectorstores/db/`.

## 4. Instalaci√≥n y Uso

Sigue estos pasos para ejecutar el proyecto en tu m√°quina local.

**Prerrequisitos:**
- Python 3.9+ instalado.
- Git instalado.

**Pasos:**

1.  **Clonar el Repositorio:**
    ```bash
    git clone <URL-del-repositorio-en-github>
    cd rag-evaluaciones-salud
    ```

2.  **Instalar Dependencias:**
    ```bash
    pip install -r requirements.txt
    ```

3.  **Descargar el Modelo LLM:**
    Este proyecto est√° configurado para usar `Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf`. Debes descargarlo y asegurarte de que la ruta en `app.py` (variable `MODEL_PATH`) apunte a la ubicaci√≥n correcta del archivo `.gguf` en tu sistema.

4.  **A√±adir Documentos Fuente:**
    Coloca todos tus archivos `.pdf` y `.docx` en la carpeta `documentos/`.

5.  **Crear la Base de Datos Vectorial:**
    Ejecuta el script de ingesta una sola vez (o cada vez que cambies los documentos).
    ```bash
    python ingest.py
    ```

6.  **Lanzar la Aplicaci√≥n:**
    ```bash
    streamlit run app.py
    ```
    Esto abrir√° una nueva pesta√±a en tu navegador web con la interfaz de la aplicaci√≥n.

## 5. Resultados y Funcionalidades Implementadas

- **Consulta en Lenguaje Natural:** Interfaz web para realizar preguntas sobre la base documental.
- **Generaci√≥n Aumentada por Recuperaci√≥n (RAG):** El sistema recupera los fragmentos m√°s relevantes de los documentos antes de generar una respuesta, asegurando que est√© fundamentada en el contexto.
- **Citas en L√≠nea:** Las respuestas incluyen marcadores de cita (ej. `[1]`, `[2]`) que se corresponden con las fuentes mostradas, permitiendo la verificaci√≥n de la informaci√≥n.
- **Control de Recuperaci√≥n (k):** La interfaz incluye un control deslizable para ajustar din√°micamente cu√°ntos fragmentos de texto se recuperan, permitiendo experimentar con el balance entre contexto y "ruido".

## 6. Pr√≥ximos Pasos y Hoja de Ruta para Evaluaci√≥n

La siguiente fase crucial es la **Evaluaci√≥n (Fase 3)** para medir objetivamente la calidad y fiabilidad del sistema.

1.  **Crear un Set de Evaluaci√≥n (Golden Set):**
    - Elaborar una lista de 20-30 preguntas representativas que cubran diferentes aspectos de los documentos.
    - Para cada pregunta, redactar la "respuesta ideal" de forma manual, basada en la lectura de los documentos.
    - Anotar qu√© documentos o fragmentos contienen la informaci√≥n necesaria para cada respuesta ideal.

2.  **Definir M√©tricas de Calidad RAG:**
    - **Faithfulness (Fidelidad):** ¬øLa respuesta generada se contradice con el contexto proporcionado? Se mide pidi√©ndole a un LLM (o a un humano) que verifique si cada afirmaci√≥n de la respuesta est√° respaldada por el contexto.
    - **Answer Relevancy (Relevancia de la Respuesta):** ¬øQu√© tan relevante es la respuesta para la pregunta del usuario? No debe desviarse del tema.
    - **Context Recall (Recuperaci√≥n del Contexto):** ¬øEl sistema recuper√≥ todos los fragmentos de texto relevantes para responder a la pregunta? Se compara con las anotaciones del Golden Set.

3.  **Implementar un Bucle de Feedback de Usuario:**
    - A√±adir botones de "pulgar arriba / pulgar abajo" (üëç/üëé) a cada respuesta en la interfaz de Streamlit.
    - Almacenar este feedback (pregunta, respuesta, contexto, calificaci√≥n) en un archivo o base de datos simple. Este feedback es extremadamente valioso para identificar debilidades y guiar futuras optimizaciones.